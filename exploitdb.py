
# author Shivang

import pycurl
from bs4 import BeautifulSoup
from googlesearch import search 

class ContentCallback:
    def __init__(self):
        self.contents = ''

    def content_callback(self, buf):
        self.contents = self.contents + buf


def exploit_db_search(name):
    if len(name) != 0:
        try:
            query = str(name) + ' ' + 'site:https://www.exploit-db.com'
            for data in  search(query, tld="com", num=20, start=0, stop=25, pause=2):
                if "https://www.exploit-db.com/exploits" in data:
                    t = ContentCallback()
                    curlObj = pycurl.Curl()
                    curlObj.setopt(curlObj.URL, '{}'.format(data))
                    curlObj.setopt(curlObj.WRITEFUNCTION, t.content_callback)
                    curlObj.perform()
                    curlObj.close()
                    print  "Url:" + ' ' + data 
                    soup = BeautifulSoup(t.contents,'lxml')
                    desc = soup.find("meta", property="og:title")
                    print "Title:" +  ' ' + desc["content"] if desc else "Cannot find the description for the exploit"
                    author = soup.find("meta", property="article:author")
                    print "Author:" + ' ' +  author["content"] if author else "No author name found"
                    publish = soup.find("meta", property="article:published_time")
                    print "Publish Date:" +  ' ' + publish["content"] if publish else "Cannot find the published date"
                    print

        except:
            print "Connection Error!"





